# EU AI Act – Risk-Based Overview (Bank / CAP Context)

## 1. Risk-Based Approach

The EU AI Act categorizes AI systems into:

- **Unacceptable risk** – prohibited.
- **High risk** – subject to strict requirements.
- **Limited risk** – transparency obligations.
- **Minimal risk** – largely unregulated.

In the bank/CAP demo context, relevant systems might include:

- Fraud detection models.
- Credit scoring models.
- Disinformation detection / monitoring systems.
- Internal decision-support agents (Org Agents, OrgQwen).

---

## 2. Requirements for High-Risk AI Systems (Simplified)

Key areas likely relevant:

- **Risk management system.**
- **Data and data governance.**
- **Technical documentation + record-keeping.**
- **Transparency and provision of information to users.**
- **Human oversight.**
- **Accuracy, robustness, and cybersecurity.**

---

## 3. How CAP Helps

CAP does NOT replace legal compliance, but helps with:

1. **Technical Documentation & Record-Keeping**
   - SBOMs for AI components and pipelines.
   - Attestations for training, validation, and deployment steps.
   - Anchored records (Canon/SCITT) for changes over time.

2. **Traceability**
   - Evidence of:
     - Which version of a model made a decision.
     - Which data pipelines were used.
   - Agent runs promoted to Evidence/Attestations as part of decision trails.

3. **Auditability**
   - Regulators and auditors can inspect:
     - Evidence.
     - Attestations.
     - Anchors.
   - Without direct access to production systems.

---

## 4. Bank / Alto Demo Angle

- The demo can show a **“light” AI Act-aligned posture**:
  - Org Agents used as **decision-support** with documented evidence.
  - CAP storing:
    - Model deployment history.
    - Data pipeline attestations.
    - Policy links for governance.

This document gives Alto / the bank a way to **talk about CAP** in the language of the EU AI Act without over-claiming full compliance.
